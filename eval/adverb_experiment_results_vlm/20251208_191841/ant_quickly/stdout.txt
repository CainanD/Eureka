[2025-12-08 19:18:45,988][root][INFO] - Workspace: /data/user_data/wenjiel2/Code/roboly/eval/adverb_experiment_results_vlm/20251208_191841/ant_quickly/outputs/eureka/2025-12-08_19-18-45
[2025-12-08 19:18:45,988][root][INFO] - Project Root: /data/user_data/wenjiel2/Code/roboly/Eureka/eureka
[2025-12-08 19:18:45,988][root][INFO] - Using LLM: gpt-4.1-mini
[2025-12-08 19:18:45,988][root][INFO] - Task: Ant
[2025-12-08 19:18:45,988][root][INFO] - Task description: make the ant walk forward quickly
[2025-12-08 19:18:45,988][root][INFO] - Number of reward samples: 2
[2025-12-08 19:18:45,988][root][INFO] - Training mode: individual
[2025-12-08 19:18:45,988][root][INFO] - VLM iterations: 1
[2025-12-08 19:18:45,988][root][INFO] - Loading checkpoint: /data/user_data/wenjiel2/Code/roboly/eval/pretrained_ant_converted.pth
[2025-12-08 19:18:46,012][root][INFO] - 
============================================================
[2025-12-08 19:18:46,012][root][INFO] - Iteration 0/1
[2025-12-08 19:18:46,012][root][INFO] - ============================================================
[2025-12-08 19:18:46,012][root][INFO] - Generating 2 reward functions with gpt-4.1-mini
[2025-12-08 19:18:54,367][httpx][INFO] - HTTP Request: POST https://ai-gateway.andrew.cmu.edu/chat/completions "HTTP/1.1 200 OK"
[2025-12-08 19:18:54,382][root][INFO] - Received 2 reward functions
[2025-12-08 19:18:54,383][root][INFO] - Reward function 0: parsed successfully
[2025-12-08 19:18:54,383][root][INFO] - Reward function 1: parsed successfully
[2025-12-08 19:18:54,383][root][INFO] - Training 2 individual policies
[2025-12-08 19:18:54,383][root][INFO] - Training policy 0/1
[2025-12-08 19:19:05,342][root][INFO] - Iteration 0: Code Run 0 execution error!
[2025-12-08 19:19:06,578][root][ERROR] - Training failed:
Traceback (most recent call last):
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/train.py", line 214, in launch_rlg_hydra
    statistics = runner.run({
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/torch_runner.py", line 124, in run
    self.run_train(args)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/torch_runner.py", line 101, in run_train
    self.agent.train()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 1260, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses, entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 1124, in train_epoch
    batch_dict = self.play_steps()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 695, in play_steps
    self.obs, rewards, self.dones, infos = self.env_step(res_dict['actions'])
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 504, in env_step
    obs, rewards, dones, infos = self.vec_env.step(actions)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/utils/rlgames_utils.py", line 256, in step
    return  self.env.step(actions)
  File "/data/user_data/wenjiel2/miniconda3/envs/eureka/lib/python3.8/site-packages/gym/wrappers/record_video.py", line 86, in step
    observations, rewards, dones, infos = super().step(action)
  File "/data/user_data/wenjiel2/miniconda3/envs/eureka/lib/python3.8/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/base/vec_task.py", line 377, in step
    self.post_physics_step()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/antgpt.py", line 248, in post_physics_step
    self.compute_reward(self.actions)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/antgpt.py", line 185, in compute_reward
    self.rew_buf[:], self.rew_dict = compute_reward(self.root_states, self.prev_potentials, self.potentials, self.velocities, self.up_vec, self.heading_vec, self.contact_force_scale)
AttributeError: 'AntGPT' object has no attribute 'velocities'

[2025-12-08 19:19:06,578][root][WARNING] - Policy 0: Training failed - training_error
[2025-12-08 19:19:06,578][root][INFO] - Training policy 1/1
[2025-12-08 19:19:16,090][root][INFO] - Iteration 0: Code Run 1 execution error!
[2025-12-08 19:19:17,271][root][ERROR] - Training failed:
Traceback (most recent call last):
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/train.py", line 214, in launch_rlg_hydra
    statistics = runner.run({
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/torch_runner.py", line 124, in run
    self.run_train(args)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/torch_runner.py", line 101, in run_train
    self.agent.train()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 1260, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses, entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 1124, in train_epoch
    batch_dict = self.play_steps()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 695, in play_steps
    self.obs, rewards, self.dones, infos = self.env_step(res_dict['actions'])
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 504, in env_step
    obs, rewards, dones, infos = self.vec_env.step(actions)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/utils/rlgames_utils.py", line 256, in step
    return  self.env.step(actions)
  File "/data/user_data/wenjiel2/miniconda3/envs/eureka/lib/python3.8/site-packages/gym/wrappers/record_video.py", line 86, in step
    observations, rewards, dones, infos = super().step(action)
  File "/data/user_data/wenjiel2/miniconda3/envs/eureka/lib/python3.8/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/base/vec_task.py", line 377, in step
    self.post_physics_step()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/antgpt.py", line 248, in post_physics_step
    self.compute_reward(self.actions)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/antgpt.py", line 188, in compute_reward
    self.gt_rew_buf, _ = compute_success(self.root_states, self.prev_potentials, self.potentials, self.velocities, self.up_vec, self.heading_vec, self.contact_force_scale)
AttributeError: 'AntGPT' object has no attribute 'velocities'

[2025-12-08 19:19:17,271][root][WARNING] - Policy 1: Training failed - training_error
[2025-12-08 19:19:17,271][root][ERROR] - All training runs failed!
[2025-12-08 19:19:17,271][root][INFO] - 
============================================================
[2025-12-08 19:19:17,271][root][INFO] - Iteration 1/1
[2025-12-08 19:19:17,271][root][INFO] - ============================================================
[2025-12-08 19:19:17,271][root][INFO] - Generating 2 reward functions with gpt-4.1-mini
[2025-12-08 19:19:25,797][httpx][INFO] - HTTP Request: POST https://ai-gateway.andrew.cmu.edu/chat/completions "HTTP/1.1 200 OK"
[2025-12-08 19:19:25,799][root][INFO] - Received 2 reward functions
[2025-12-08 19:19:25,799][root][INFO] - Reward function 0: parsed successfully
[2025-12-08 19:19:25,799][root][INFO] - Reward function 1: parsed successfully
[2025-12-08 19:19:25,799][root][INFO] - Training 2 individual policies
[2025-12-08 19:19:25,799][root][INFO] - Training policy 0/1
[2025-12-08 19:19:35,107][root][INFO] - Iteration 1: Code Run 0 execution error!
[2025-12-08 19:19:36,262][root][ERROR] - Training failed:
Traceback (most recent call last):
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/train.py", line 214, in launch_rlg_hydra
    statistics = runner.run({
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/torch_runner.py", line 124, in run
    self.run_train(args)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/torch_runner.py", line 101, in run_train
    self.agent.train()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 1260, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses, entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 1124, in train_epoch
    batch_dict = self.play_steps()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 695, in play_steps
    self.obs, rewards, self.dones, infos = self.env_step(res_dict['actions'])
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 504, in env_step
    obs, rewards, dones, infos = self.vec_env.step(actions)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/utils/rlgames_utils.py", line 256, in step
    return  self.env.step(actions)
  File "/data/user_data/wenjiel2/miniconda3/envs/eureka/lib/python3.8/site-packages/gym/wrappers/record_video.py", line 86, in step
    observations, rewards, dones, infos = super().step(action)
  File "/data/user_data/wenjiel2/miniconda3/envs/eureka/lib/python3.8/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/base/vec_task.py", line 377, in step
    self.post_physics_step()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/antgpt.py", line 248, in post_physics_step
    self.compute_reward(self.actions)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/antgpt.py", line 188, in compute_reward
    self.gt_rew_buf, _ = compute_success(self.root_states, self.prev_potentials, self.potentials, self.velocities, self.up_vec, self.heading_vec, self.contact_force_scale)
AttributeError: 'AntGPT' object has no attribute 'velocities'

[2025-12-08 19:19:36,263][root][WARNING] - Policy 0: Training failed - training_error
[2025-12-08 19:19:36,263][root][INFO] - Training policy 1/1
[2025-12-08 19:19:45,633][root][INFO] - Iteration 1: Code Run 1 execution error!
[2025-12-08 19:19:46,799][root][ERROR] - Training failed:
Traceback (most recent call last):
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/train.py", line 214, in launch_rlg_hydra
    statistics = runner.run({
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/torch_runner.py", line 124, in run
    self.run_train(args)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/torch_runner.py", line 101, in run_train
    self.agent.train()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 1260, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses, entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 1124, in train_epoch
    batch_dict = self.play_steps()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 695, in play_steps
    self.obs, rewards, self.dones, infos = self.env_step(res_dict['actions'])
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/rl_games/rl_games/common/a2c_common.py", line 504, in env_step
    obs, rewards, dones, infos = self.vec_env.step(actions)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/utils/rlgames_utils.py", line 256, in step
    return  self.env.step(actions)
  File "/data/user_data/wenjiel2/miniconda3/envs/eureka/lib/python3.8/site-packages/gym/wrappers/record_video.py", line 86, in step
    observations, rewards, dones, infos = super().step(action)
  File "/data/user_data/wenjiel2/miniconda3/envs/eureka/lib/python3.8/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/base/vec_task.py", line 377, in step
    self.post_physics_step()
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/antgpt.py", line 248, in post_physics_step
    self.compute_reward(self.actions)
  File "/data/user_data/wenjiel2/Code/roboly/Eureka/isaacgymenvs/isaacgymenvs/tasks/antgpt.py", line 188, in compute_reward
    self.gt_rew_buf, _ = compute_success(self.root_states, self.prev_potentials, self.potentials, self.velocities, self.up_vec, self.heading_vec, self.contact_force_scale)
AttributeError: 'AntGPT' object has no attribute 'velocities'

[2025-12-08 19:19:46,799][root][WARNING] - Policy 1: Training failed - training_error
[2025-12-08 19:19:46,799][root][ERROR] - All training runs failed!
[2025-12-08 19:19:46,799][root][INFO] - 
============================================================
[2025-12-08 19:19:46,799][root][INFO] - TRAINING COMPLETE
[2025-12-08 19:19:46,799][root][INFO] - ============================================================
[2025-12-08 19:19:46,799][root][ERROR] - No successful training runs!
[2025-12-08 19:19:46,799][root][INFO] - Done!

